new

Get trending papers in your email inbox once a day!

Get trending papers in your email inbox!

[Subscribe](/login?next=%2Fpapers)

# [Daily Papers](/papers)

## by [![](/front/assets/papers-by.png)AK](/akhaliq) and the research community

Search by arxiv id or title
`Ctrl+K`

[Submit a paper](/spaces/huggingface/HuggingDiscussions/discussions/32)

Jan13

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05874.png)](/papers/2501.05874)

Submitted by
![](/avatars/a7eb03f5cbd4eaa09fe807bbed8bc0f7.svg) jinheon

[38](/login?next=%2Fpapers%2F2501.05874)

### [VideoRAG: Retrieval-Augmented Generation over Video Corpus](/papers/2501.05874)

[- ![](/avatars/a7eb03f5cbd4eaa09fe807bbed8bc0f7.svg)\\
- ![](/avatars/f45eea356e92ac7b3db23c2c92dec9fa.svg)\\
- ![](/avatars/d7ffe7fbbe39c0a013375357457c57b3.svg)\\
- ·\\
\\
4 authors](/papers/2501.05874)[3](/papers/2501.05874#community)

Submitted by
![](/avatars/faad88525197bb6c63be0068f19de418.svg) pmj110119

[36](/login?next=%2Fpapers%2F2501.03841)

### [OmniManip: Towards General Robotic Manipulation via Object-Centric Interaction Primitives as Spatial Constraints](/papers/2501.03841)

[- ![](https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/xCgJ6I7-rATf5J1A5tCJM.png)\\
- ![](/avatars/d2b5bd89535618a8ca383a3dd2537055.svg)\\
- ![](/avatars/faad88525197bb6c63be0068f19de418.svg)\\
- ·\\
\\
6 authors](/papers/2501.03841)[1](/papers/2501.03841#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06186.png)](/papers/2501.06186)

Submitted by
![](https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg) ahmedheakl

[31](/login?next=%2Fpapers%2F2501.06186)

### [LlamaV-o1: Rethinking Step-by-step Visual Reasoning in LLMs](/papers/2501.06186)

[- ![](/avatars/ac0d7eef62cd98a280b162cf7896b1a2.svg)\\
- ![](https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg)\\
- ![](/avatars/69007f7e7f7ff78069101deb4b354e37.svg)\\
- ![](/avatars/76c31ea218108cf6c3715269f7605404.svg)\\
- ·\\
\\
15 authors](/papers/2501.06186)[1](/papers/2501.06186#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05510.png)](/papers/2501.05510)

Submitted by
![](/avatars/bcc9bf5cbf67546ad2b4c9ec8b96ac96.svg) myownskyW7

[25](/login?next=%2Fpapers%2F2501.05510)

### [OVO-Bench: How Far is Your Video-LLMs from Real-World Online Video Understanding?](/papers/2501.05510)

[- ![](/avatars/41b94d1b3f51e4bb070f291f80fcafd8.svg)\\
- ![](https://cdn-avatars.huggingface.co/v1/production/uploads/1594864762501-noauth.jpeg)\\
- ![](/avatars/9614510443bee3bd5d6266efd1c39fc1.svg)\\
- ![](/avatars/f09ff031c278bc42bfd7a563853e142c.svg)\\
- ![](/avatars/883f6ba38b993476115dfafcef9ce3c1.svg)\\
- ·\\
\\
15 authors](/papers/2501.05510)[1](/papers/2501.05510#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05727.png)](/papers/2501.05727)

Submitted by
![](/avatars/c0615f8c6606073faffb419757d4e667.svg) tangzhy

[16](/login?next=%2Fpapers%2F2501.05727)

### [Enabling Scalable Oversight via Self-Evolving Critic](/papers/2501.05727)

[- ![](https://cdn-avatars.huggingface.co/v1/production/uploads/6434d4989bd5a84b5dd0b0f5/0Elf9qbfG9Hkgypm9pTGm.jpeg)\\
- ![](/avatars/288ed63a1efa566c3f01e850c6ba5dd5.svg)\\
- ![](/avatars/2a0b47328a780f24a640933111fe163c.svg)\\
- ![](/avatars/b4399d210d7239d4662b11a4ee7b527d.svg)\\
- ![](/avatars/c0615f8c6606073faffb419757d4e667.svg)\\
- ·\\
\\
11 authors](/papers/2501.05727)[1](/papers/2501.05727#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05452.png)](/papers/2501.05452)

Submitted by
![](/avatars/4d29cef783603dc8ba123f01cde93ad8.svg) Fiaa

[7](/login?next=%2Fpapers%2F2501.05452)

### [ReFocus: Visual Editing as a Chain of Thought for Structured Image Understanding](/papers/2501.05452)

[- ![](/avatars/d7eadb22aa3d8a067189b924767864e9.svg)\\
- ![](https://cdn-avatars.huggingface.co/v1/production/uploads/1629871954341-noauth.jpeg)\\
- ![](/avatars/fb36f69f03421c3a2a7f72ba0858fa60.svg)\\
- ![](/avatars/4186c592b00aea73fb8c5bb719935ce7.svg)\\
- ![](/avatars/4d29cef783603dc8ba123f01cde93ad8.svg)\\
- ·\\
\\
9 authors](/papers/2501.05452)[1](/papers/2501.05452#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04698.png)](/papers/2501.04698)

Submitted by
![](https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg) BestWishYsh

[6](/login?next=%2Fpapers%2F2501.04698)

### [ConceptMaster: Multi-Concept Video Customization on Diffusion Transformer Models Without Test-Time Tuning](/papers/2501.04698)

[- ![](/avatars/cec7dcadf4657bb4f61e2c9a8075521b.svg)\\
- ![](https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg)\\
- ![](/avatars/ee56e7985599314c6c7076300dbde884.svg)\\
- ![](/avatars/a3b75d6945f1608e64a2fcff887a5024.svg)\\
- ![](/avatars/9ef727d5f2abacad6668a1996bbb2043.svg)\\
- ·\\
\\
9 authors](/papers/2501.04698) [1](/papers/2501.04698#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05707.png)](/papers/2501.05707)

Submitted by
![](https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg) akhaliq

[5](/login?next=%2Fpapers%2F2501.05707)

### [Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains](/papers/2501.05707)

[- ![](/avatars/a5384b63bb615192f6fa157c6ea89e92.svg)\\
- ![](/avatars/def472d1ab3fbf751225357c0932ae7e.svg)\\
- ![](/avatars/f6bb94fe302b1627b27f533ba6c32ed3.svg)\\
- ·\\
\\
6 authors](/papers/2501.05707) [1](/papers/2501.05707#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.06187.png)](/papers/2501.06187)

Submitted by
![](https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg) BestWishYsh

[4](/login?next=%2Fpapers%2F2501.06187)

### [Multi-subject Open-set Personalization in Video Generation](/papers/2501.06187)

[- ![](/avatars/d7e97a16cfee39e1e50d7a5b747876f1.svg)\\
- ![](/avatars/781f3cd455596f7cffa0906cc487f79b.svg)\\
- ![](/avatars/3b089a25a87c2e83c6b23ccb5d2dc73e.svg)\\
- ![](/avatars/76f933cd549f10e5e2db379de235d304.svg)\\
- ![](/avatars/5b394a72f277aa6c886b21b477010ab0.svg)\\
- ·\\
\\
10 authors](/papers/2501.06187) [1](/papers/2501.06187#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.05542.png)](/papers/2501.05542)

Submitted by
![](https://cdn-avatars.huggingface.co/v1/production/uploads/63136a82e29fb2e86d5e5bdd/pFZDuQtzfUStovbwwZGvn.png) dnoever

[4](/login?next=%2Fpapers%2F2501.05542)

### [Infecting Generative AI With Viruses](/papers/2501.05542)

[- ![](/avatars/12518ccef145f343548b3fd7be5efddc.svg)\\
- ![](https://cdn-avatars.huggingface.co/v1/production/uploads/63136a82e29fb2e86d5e5bdd/pFZDuQtzfUStovbwwZGvn.png)\\
- ·\\
\\
2 authors](/papers/2501.05542)[2](/papers/2501.05542#community)

[![](https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.04961.png)](/papers/2501.04961)

Submitted by
![](/avatars/39c7ac4c8036c2fe37e68d20f6864985.svg) ZixuanKe

[3](/login?next=%2Fpapers%2F2501.04961)

### [Demystifying Domain-adaptive Post-training for Financial LLMs](/papers/2501.04961)

[- ![](/avatars/39c7ac4c8036c2fe37e68d20f6864985.svg)\\
- ·\\
\\
5 authors](/papers/2501.04961)[1](/papers/2501.04961#community)

[Previous](/papers?date=2025-01-10)
